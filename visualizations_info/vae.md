
---
### Objective
Shows the VAE loss, which typically consists of a **Reconstruction Loss** (how well the model can recreate its input user-item interaction vector after encoding and decoding it) and a **KL Divergence** loss (which encourages the learned latent distribution to be close to a prior, usually a standard normal distribution N(0,1)). A decreasing trend indicates the model is learning both to represent user preferences compactly and to structure the latent space effectively, leading to convergence.

---
### Latent Distribution
This plot shows the distribution of the learned latent variable 'Î¼' (mean) vectors generated by the VAE's encoder for the training data (or a batch). It compares this distribution to the 'prior' distribution (a standard N(0,1) normal distribution) that the KL divergence term encourages it to match. A good VAE learns a latent distribution ('Latent Value Distribution') that is reasonably close to the prior ('Standard Normal Prior'), which helps in generating diverse and meaningful recommendations and encourages a well-structured, smooth latent space.

---
### Reconstruction Heatmap
This visualization compares a batch of original user-item interactions (usually binarized for implicit feedback) against the model's reconstructed output scores for that same batch, typically from the last training epoch.
* **Original Batch:** Shows the actual input vectors (e.g., which items users interacted with).
* **Reconstructed Batch:** Shows the output scores from the VAE's decoder. Higher scores indicate items the model believes the user is likely to interact with based on their learned latent representation.
  Comparing the two helps assess how well the VAE learned to capture and recreate the essential patterns in user preferences. Bright spots in the reconstruction corresponding to bright spots in the original indicate successful reconstruction.